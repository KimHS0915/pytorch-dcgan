{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dcgan_face.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHv1O-fTvwsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYZAz3OtDTFS",
        "colab_type": "code",
        "outputId": "8f90d165-5641-4aff-cff4-4d937ea4a32a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "manualSeed = random.randint(1, 10000)\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Seed:  1933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f25e9db8030>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRXpXq8GYFZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bKmv7pGDiI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataroot = \"/content/gdrive/My Drive/Colab Notebooks/pytorch/face\"\n",
        "workers = 2\n",
        "batch_size = 128\n",
        "nc = 3\n",
        "nz = 100\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "num_epochs = 250\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "ngpu = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDHvnYSiEUkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dset.ImageFolder(root=dataroot,\n",
        "                           transform=transforms.Compose([transforms.ToTensor(),\n",
        "                                                         transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                                                                             (0.5, 0.5, 0.5))]))\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPQhMpXN38E1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_batch = next(iter(dataloader))\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2,\n",
        "                                         normalize=True).cpu(),(1,2,0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofesDtW-Zsd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQbRjcfjaStq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "\n",
        "            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "\n",
        "        )\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gHFOg6wdQEE",
        "colab_type": "code",
        "outputId": "25f9bf81-6409-4ae5-d6a2-931322449b6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "netG = Generator(ngpu).to(device)\n",
        "\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netg = nn.DataParallel(netG, list(range(ngpu)))\n",
        "\n",
        "netG.apply(weights_init)\n",
        "\n",
        "print(netG)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (main): Sequential(\n",
            "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (13): Tanh()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lORhJMkelth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf*2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf*4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf*8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(ndf*8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0XRDmdCj6da",
        "colab_type": "code",
        "outputId": "a7490486-b327-40d4-c082-0030873b6fee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "netD = Discriminator(ngpu).to(device)\n",
        "\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
        "\n",
        "netD.apply(weights_init)\n",
        "\n",
        "print(netD)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (12): Sigmoid()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4R8pnJXkgxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCELoss()\n",
        "\n",
        "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh5mkWGqk5cY",
        "colab_type": "code",
        "outputId": "e91ffba4-b4c3-4f18-d837-0af2d05a135b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Update D network\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        netD.zero_grad()\n",
        "        real_cpu = data[0].to(device)\n",
        "        b_size = real_cpu.size(0)\n",
        "        label = torch.full((b_size,), real_label, device=device)\n",
        "\n",
        "        output = netD(real_cpu).view(-1)\n",
        "\n",
        "        errD_real = criterion(output, label)\n",
        "\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "\n",
        "        fake=netG(noise)\n",
        "        label.fill_(fake_label)\n",
        "        output = netD(fake.detach()).view(-1)\n",
        "\n",
        "        errD_fake = criterion(output, label)\n",
        "\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "\n",
        "        errD = errD_real + errD_fake\n",
        "\n",
        "        optimizerD.step()\n",
        "\n",
        "        # Update G network\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)\n",
        "\n",
        "        output = netD(fake).view(-1)\n",
        "\n",
        "        errG = criterion(output, label)\n",
        "\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "\n",
        "        optimizerG.step()\n",
        "\n",
        "        # Output training stats\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, num_epochs, i, len(dataloader),\n",
        "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "        \n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        # Check how the generator is doing by saving G's output on fixed_noise\n",
        "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
        "            with torch.no_grad():\n",
        "                fake = netG(fixed_noise).detach().cpu()\n",
        "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "\n",
        "        iters += 1 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Training Loop...\n",
            "[0/250][0/29]\tLoss_D: 1.4188\tLoss_G: 2.6185\tD(x): 0.4365\tD(G(z)): 0.2754 / 0.0991\n",
            "[1/250][0/29]\tLoss_D: 0.0248\tLoss_G: 14.1254\tD(x): 0.9843\tD(G(z)): 0.0000 / 0.0000\n",
            "[2/250][0/29]\tLoss_D: 1.6332\tLoss_G: 24.0437\tD(x): 0.4819\tD(G(z)): 0.0000 / 0.0000\n",
            "[3/250][0/29]\tLoss_D: 0.2688\tLoss_G: 5.6804\tD(x): 0.9798\tD(G(z)): 0.1460 / 0.0229\n",
            "[4/250][0/29]\tLoss_D: 0.3186\tLoss_G: 6.5989\tD(x): 0.9552\tD(G(z)): 0.1490 / 0.0087\n",
            "[5/250][0/29]\tLoss_D: 0.9961\tLoss_G: 5.5826\tD(x): 0.6107\tD(G(z)): 0.0092 / 0.0083\n",
            "[6/250][0/29]\tLoss_D: 0.5828\tLoss_G: 5.1983\tD(x): 0.7357\tD(G(z)): 0.0197 / 0.0109\n",
            "[7/250][0/29]\tLoss_D: 0.8804\tLoss_G: 9.1109\tD(x): 0.9749\tD(G(z)): 0.4680 / 0.0006\n",
            "[8/250][0/29]\tLoss_D: 0.1997\tLoss_G: 5.7041\tD(x): 0.8772\tD(G(z)): 0.0069 / 0.0077\n",
            "[9/250][0/29]\tLoss_D: 0.6854\tLoss_G: 5.3250\tD(x): 0.6735\tD(G(z)): 0.0130 / 0.0115\n",
            "[10/250][0/29]\tLoss_D: 0.7002\tLoss_G: 7.7391\tD(x): 0.8827\tD(G(z)): 0.3496 / 0.0012\n",
            "[11/250][0/29]\tLoss_D: 0.4593\tLoss_G: 5.6023\tD(x): 0.7557\tD(G(z)): 0.0258 / 0.0122\n",
            "[12/250][0/29]\tLoss_D: 0.3795\tLoss_G: 7.7478\tD(x): 0.9236\tD(G(z)): 0.1993 / 0.0011\n",
            "[13/250][0/29]\tLoss_D: 0.2938\tLoss_G: 4.6685\tD(x): 0.9667\tD(G(z)): 0.1813 / 0.0310\n",
            "[14/250][0/29]\tLoss_D: 0.7049\tLoss_G: 5.7772\tD(x): 0.7940\tD(G(z)): 0.2582 / 0.0070\n",
            "[15/250][0/29]\tLoss_D: 0.8116\tLoss_G: 9.3108\tD(x): 0.9636\tD(G(z)): 0.4765 / 0.0004\n",
            "[16/250][0/29]\tLoss_D: 0.4700\tLoss_G: 3.1618\tD(x): 0.7519\tD(G(z)): 0.0557 / 0.0725\n",
            "[17/250][0/29]\tLoss_D: 0.4958\tLoss_G: 4.1460\tD(x): 0.8352\tD(G(z)): 0.2225 / 0.0281\n",
            "[18/250][0/29]\tLoss_D: 1.6961\tLoss_G: 4.0017\tD(x): 0.3616\tD(G(z)): 0.0043 / 0.0404\n",
            "[19/250][0/29]\tLoss_D: 0.7144\tLoss_G: 3.8628\tD(x): 0.6521\tD(G(z)): 0.0156 / 0.0337\n",
            "[20/250][0/29]\tLoss_D: 0.4526\tLoss_G: 5.5762\tD(x): 0.8605\tD(G(z)): 0.2172 / 0.0072\n",
            "[21/250][0/29]\tLoss_D: 0.3631\tLoss_G: 4.4917\tD(x): 0.7827\tD(G(z)): 0.0165 / 0.0195\n",
            "[22/250][0/29]\tLoss_D: 0.5233\tLoss_G: 3.7957\tD(x): 0.6952\tD(G(z)): 0.0334 / 0.0485\n",
            "[23/250][0/29]\tLoss_D: 0.5199\tLoss_G: 7.2448\tD(x): 0.9447\tD(G(z)): 0.3432 / 0.0014\n",
            "[24/250][0/29]\tLoss_D: 0.2281\tLoss_G: 3.6241\tD(x): 0.9387\tD(G(z)): 0.1317 / 0.0503\n",
            "[25/250][0/29]\tLoss_D: 0.5578\tLoss_G: 4.0102\tD(x): 0.6705\tD(G(z)): 0.0220 / 0.0419\n",
            "[26/250][0/29]\tLoss_D: 0.5512\tLoss_G: 5.4263\tD(x): 0.8615\tD(G(z)): 0.2569 / 0.0100\n",
            "[27/250][0/29]\tLoss_D: 0.7538\tLoss_G: 3.1103\tD(x): 0.5731\tD(G(z)): 0.0185 / 0.0766\n",
            "[28/250][0/29]\tLoss_D: 0.3504\tLoss_G: 3.0616\tD(x): 0.8332\tD(G(z)): 0.1244 / 0.0631\n",
            "[29/250][0/29]\tLoss_D: 0.4233\tLoss_G: 4.9329\tD(x): 0.8887\tD(G(z)): 0.2227 / 0.0124\n",
            "[30/250][0/29]\tLoss_D: 0.3803\tLoss_G: 4.8646\tD(x): 0.9246\tD(G(z)): 0.2222 / 0.0148\n",
            "[31/250][0/29]\tLoss_D: 0.1832\tLoss_G: 4.8509\tD(x): 0.9113\tD(G(z)): 0.0723 / 0.0128\n",
            "[32/250][0/29]\tLoss_D: 0.3294\tLoss_G: 4.1272\tD(x): 0.8723\tD(G(z)): 0.1479 / 0.0289\n",
            "[33/250][0/29]\tLoss_D: 0.2895\tLoss_G: 3.3367\tD(x): 0.8806\tD(G(z)): 0.1204 / 0.0545\n",
            "[34/250][0/29]\tLoss_D: 0.3720\tLoss_G: 4.8439\tD(x): 0.7573\tD(G(z)): 0.0223 / 0.0149\n",
            "[35/250][0/29]\tLoss_D: 0.5059\tLoss_G: 4.3445\tD(x): 0.8470\tD(G(z)): 0.2413 / 0.0222\n",
            "[36/250][0/29]\tLoss_D: 0.4958\tLoss_G: 4.3880\tD(x): 0.8183\tD(G(z)): 0.2128 / 0.0198\n",
            "[37/250][0/29]\tLoss_D: 1.3192\tLoss_G: 3.8352\tD(x): 0.3667\tD(G(z)): 0.0027 / 0.0390\n",
            "[38/250][0/29]\tLoss_D: 2.0505\tLoss_G: 4.2787\tD(x): 0.2546\tD(G(z)): 0.0018 / 0.0383\n",
            "[39/250][0/29]\tLoss_D: 0.3728\tLoss_G: 3.2609\tD(x): 0.7831\tD(G(z)): 0.0702 / 0.0550\n",
            "[40/250][0/29]\tLoss_D: 0.8389\tLoss_G: 0.9315\tD(x): 0.5252\tD(G(z)): 0.0380 / 0.4431\n",
            "[41/250][0/29]\tLoss_D: 0.2541\tLoss_G: 4.8288\tD(x): 0.8474\tD(G(z)): 0.0628 / 0.0173\n",
            "[42/250][0/29]\tLoss_D: 0.3162\tLoss_G: 3.0723\tD(x): 0.8038\tD(G(z)): 0.0569 / 0.0645\n",
            "[43/250][0/29]\tLoss_D: 0.4520\tLoss_G: 4.2388\tD(x): 0.8299\tD(G(z)): 0.1896 / 0.0243\n",
            "[44/250][0/29]\tLoss_D: 0.4119\tLoss_G: 3.2946\tD(x): 0.8205\tD(G(z)): 0.1586 / 0.0546\n",
            "[45/250][0/29]\tLoss_D: 0.5375\tLoss_G: 2.0262\tD(x): 0.6865\tD(G(z)): 0.0719 / 0.1773\n",
            "[46/250][0/29]\tLoss_D: 0.6374\tLoss_G: 6.4647\tD(x): 0.9537\tD(G(z)): 0.3994 / 0.0031\n",
            "[47/250][0/29]\tLoss_D: 0.7671\tLoss_G: 7.4021\tD(x): 0.9535\tD(G(z)): 0.4438 / 0.0013\n",
            "[48/250][0/29]\tLoss_D: 0.3837\tLoss_G: 3.6624\tD(x): 0.8675\tD(G(z)): 0.1881 / 0.0404\n",
            "[49/250][0/29]\tLoss_D: 0.3593\tLoss_G: 4.2786\tD(x): 0.9082\tD(G(z)): 0.2104 / 0.0204\n",
            "[50/250][0/29]\tLoss_D: 0.6882\tLoss_G: 6.5075\tD(x): 0.8758\tD(G(z)): 0.3627 / 0.0035\n",
            "[51/250][0/29]\tLoss_D: 0.3442\tLoss_G: 3.8248\tD(x): 0.8819\tD(G(z)): 0.1796 / 0.0308\n",
            "[52/250][0/29]\tLoss_D: 0.3699\tLoss_G: 3.5371\tD(x): 0.8524\tD(G(z)): 0.1655 / 0.0440\n",
            "[53/250][0/29]\tLoss_D: 0.3994\tLoss_G: 2.7874\tD(x): 0.7792\tD(G(z)): 0.1117 / 0.0865\n",
            "[54/250][0/29]\tLoss_D: 0.3341\tLoss_G: 3.9436\tD(x): 0.8821\tD(G(z)): 0.1707 / 0.0267\n",
            "[55/250][0/29]\tLoss_D: 0.3583\tLoss_G: 3.9701\tD(x): 0.7869\tD(G(z)): 0.0783 / 0.0354\n",
            "[56/250][0/29]\tLoss_D: 0.3173\tLoss_G: 3.0889\tD(x): 0.8445\tD(G(z)): 0.1194 / 0.0598\n",
            "[57/250][0/29]\tLoss_D: 0.6301\tLoss_G: 6.6592\tD(x): 0.9573\tD(G(z)): 0.4074 / 0.0026\n",
            "[58/250][0/29]\tLoss_D: 0.4462\tLoss_G: 2.8483\tD(x): 0.7287\tD(G(z)): 0.0883 / 0.0840\n",
            "[59/250][0/29]\tLoss_D: 0.3365\tLoss_G: 3.1908\tD(x): 0.8336\tD(G(z)): 0.1252 / 0.0578\n",
            "[60/250][0/29]\tLoss_D: 0.3163\tLoss_G: 2.8381\tD(x): 0.8397\tD(G(z)): 0.1155 / 0.0829\n",
            "[61/250][0/29]\tLoss_D: 0.9011\tLoss_G: 5.5721\tD(x): 0.9141\tD(G(z)): 0.4875 / 0.0058\n",
            "[62/250][0/29]\tLoss_D: 0.4000\tLoss_G: 3.3690\tD(x): 0.7362\tD(G(z)): 0.0485 / 0.0578\n",
            "[63/250][0/29]\tLoss_D: 0.3659\tLoss_G: 2.5366\tD(x): 0.8072\tD(G(z)): 0.1191 / 0.1053\n",
            "[64/250][0/29]\tLoss_D: 0.5900\tLoss_G: 5.6264\tD(x): 0.9810\tD(G(z)): 0.3956 / 0.0057\n",
            "[65/250][0/29]\tLoss_D: 0.8830\tLoss_G: 1.7143\tD(x): 0.5364\tD(G(z)): 0.0925 / 0.2469\n",
            "[66/250][0/29]\tLoss_D: 0.3696\tLoss_G: 2.8595\tD(x): 0.8328\tD(G(z)): 0.1518 / 0.0769\n",
            "[67/250][0/29]\tLoss_D: 0.5659\tLoss_G: 5.6529\tD(x): 0.9649\tD(G(z)): 0.3738 / 0.0056\n",
            "[68/250][0/29]\tLoss_D: 1.9243\tLoss_G: 7.9522\tD(x): 0.9951\tD(G(z)): 0.7824 / 0.0012\n",
            "[69/250][0/29]\tLoss_D: 0.4389\tLoss_G: 4.0603\tD(x): 0.8802\tD(G(z)): 0.2423 / 0.0257\n",
            "[70/250][0/29]\tLoss_D: 0.3619\tLoss_G: 2.7581\tD(x): 0.8017\tD(G(z)): 0.1117 / 0.0882\n",
            "[71/250][0/29]\tLoss_D: 0.3453\tLoss_G: 4.1787\tD(x): 0.9005\tD(G(z)): 0.1950 / 0.0222\n",
            "[72/250][0/29]\tLoss_D: 0.3175\tLoss_G: 3.3120\tD(x): 0.8917\tD(G(z)): 0.1694 / 0.0515\n",
            "[73/250][0/29]\tLoss_D: 1.8254\tLoss_G: 5.9351\tD(x): 0.9715\tD(G(z)): 0.7540 / 0.0073\n",
            "[74/250][0/29]\tLoss_D: 0.3074\tLoss_G: 3.6053\tD(x): 0.8901\tD(G(z)): 0.1584 / 0.0375\n",
            "[75/250][0/29]\tLoss_D: 0.3183\tLoss_G: 2.8339\tD(x): 0.8284\tD(G(z)): 0.1056 / 0.0790\n",
            "[76/250][0/29]\tLoss_D: 0.3341\tLoss_G: 2.3130\tD(x): 0.8131\tD(G(z)): 0.0945 / 0.1349\n",
            "[77/250][0/29]\tLoss_D: 0.2363\tLoss_G: 2.3675\tD(x): 0.8842\tD(G(z)): 0.0937 / 0.1239\n",
            "[78/250][0/29]\tLoss_D: 0.9570\tLoss_G: 1.6545\tD(x): 0.5455\tD(G(z)): 0.1688 / 0.2625\n",
            "[79/250][0/29]\tLoss_D: 0.4454\tLoss_G: 2.8047\tD(x): 0.7422\tD(G(z)): 0.0929 / 0.0882\n",
            "[80/250][0/29]\tLoss_D: 0.2842\tLoss_G: 3.4424\tD(x): 0.9058\tD(G(z)): 0.1593 / 0.0429\n",
            "[81/250][0/29]\tLoss_D: 0.2539\tLoss_G: 3.4186\tD(x): 0.8169\tD(G(z)): 0.0370 / 0.0453\n",
            "[82/250][0/29]\tLoss_D: 0.5848\tLoss_G: 5.8419\tD(x): 0.9716\tD(G(z)): 0.3818 / 0.0050\n",
            "[83/250][0/29]\tLoss_D: 0.4076\tLoss_G: 3.0876\tD(x): 0.8199\tD(G(z)): 0.1607 / 0.0675\n",
            "[84/250][0/29]\tLoss_D: 0.3305\tLoss_G: 2.3915\tD(x): 0.8433\tD(G(z)): 0.1289 / 0.1138\n",
            "[85/250][0/29]\tLoss_D: 0.5313\tLoss_G: 2.3691\tD(x): 0.6295\tD(G(z)): 0.0149 / 0.1380\n",
            "[86/250][0/29]\tLoss_D: 1.3307\tLoss_G: 7.2154\tD(x): 0.9710\tD(G(z)): 0.6595 / 0.0014\n",
            "[87/250][0/29]\tLoss_D: 0.2946\tLoss_G: 3.3054\tD(x): 0.8348\tD(G(z)): 0.0899 / 0.0515\n",
            "[88/250][0/29]\tLoss_D: 0.7083\tLoss_G: 6.1123\tD(x): 0.9776\tD(G(z)): 0.4501 / 0.0037\n",
            "[89/250][0/29]\tLoss_D: 0.6000\tLoss_G: 1.8165\tD(x): 0.5989\tD(G(z)): 0.0203 / 0.2239\n",
            "[90/250][0/29]\tLoss_D: 3.2496\tLoss_G: 0.0502\tD(x): 0.0792\tD(G(z)): 0.0032 / 0.9530\n",
            "[91/250][0/29]\tLoss_D: 0.3341\tLoss_G: 2.8801\tD(x): 0.8513\tD(G(z)): 0.1446 / 0.0738\n",
            "[92/250][0/29]\tLoss_D: 0.4024\tLoss_G: 5.1522\tD(x): 0.9550\tD(G(z)): 0.2752 / 0.0084\n",
            "[93/250][0/29]\tLoss_D: 0.3080\tLoss_G: 2.7874\tD(x): 0.8541\tD(G(z)): 0.1253 / 0.0877\n",
            "[94/250][0/29]\tLoss_D: 0.5635\tLoss_G: 2.6323\tD(x): 0.6739\tD(G(z)): 0.0884 / 0.1106\n",
            "[95/250][0/29]\tLoss_D: 0.3075\tLoss_G: 3.0666\tD(x): 0.8529\tD(G(z)): 0.1285 / 0.0621\n",
            "[96/250][0/29]\tLoss_D: 0.2419\tLoss_G: 3.6243\tD(x): 0.9017\tD(G(z)): 0.1206 / 0.0356\n",
            "[97/250][0/29]\tLoss_D: 0.3230\tLoss_G: 3.8921\tD(x): 0.9166\tD(G(z)): 0.1947 / 0.0279\n",
            "[98/250][0/29]\tLoss_D: 0.2624\tLoss_G: 3.0978\tD(x): 0.9179\tD(G(z)): 0.1519 / 0.0616\n",
            "[99/250][0/29]\tLoss_D: 0.3859\tLoss_G: 3.7529\tD(x): 0.8224\tD(G(z)): 0.1429 / 0.0427\n",
            "[100/250][0/29]\tLoss_D: 0.2332\tLoss_G: 3.3841\tD(x): 0.8919\tD(G(z)): 0.1055 / 0.0475\n",
            "[101/250][0/29]\tLoss_D: 0.3191\tLoss_G: 4.5693\tD(x): 0.9592\tD(G(z)): 0.2240 / 0.0152\n",
            "[102/250][0/29]\tLoss_D: 0.3185\tLoss_G: 3.7282\tD(x): 0.8572\tD(G(z)): 0.1350 / 0.0350\n",
            "[103/250][0/29]\tLoss_D: 0.6232\tLoss_G: 6.3846\tD(x): 0.9598\tD(G(z)): 0.3980 / 0.0029\n",
            "[104/250][0/29]\tLoss_D: 0.3811\tLoss_G: 4.4439\tD(x): 0.8892\tD(G(z)): 0.2102 / 0.0167\n",
            "[105/250][0/29]\tLoss_D: 0.3275\tLoss_G: 3.4389\tD(x): 0.8734\tD(G(z)): 0.1599 / 0.0424\n",
            "[106/250][0/29]\tLoss_D: 0.2849\tLoss_G: 3.5946\tD(x): 0.9499\tD(G(z)): 0.1968 / 0.0354\n",
            "[107/250][0/29]\tLoss_D: 0.6354\tLoss_G: 6.3123\tD(x): 0.9749\tD(G(z)): 0.4119 / 0.0028\n",
            "[108/250][0/29]\tLoss_D: 0.6961\tLoss_G: 2.1182\tD(x): 0.5846\tD(G(z)): 0.0514 / 0.1822\n",
            "[109/250][0/29]\tLoss_D: 0.2993\tLoss_G: 2.6987\tD(x): 0.7996\tD(G(z)): 0.0550 / 0.0914\n",
            "[110/250][0/29]\tLoss_D: 0.3181\tLoss_G: 4.5626\tD(x): 0.9544\tD(G(z)): 0.2227 / 0.0135\n",
            "[111/250][0/29]\tLoss_D: 1.7631\tLoss_G: 1.2492\tD(x): 0.2206\tD(G(z)): 0.0029 / 0.3800\n",
            "[112/250][0/29]\tLoss_D: 1.6101\tLoss_G: 7.6383\tD(x): 0.9820\tD(G(z)): 0.7369 / 0.0010\n",
            "[113/250][0/29]\tLoss_D: 0.2834\tLoss_G: 3.9501\tD(x): 0.9352\tD(G(z)): 0.1818 / 0.0256\n",
            "[114/250][0/29]\tLoss_D: 0.3154\tLoss_G: 2.3841\tD(x): 0.7639\tD(G(z)): 0.0318 / 0.1175\n",
            "[115/250][0/29]\tLoss_D: 0.2503\tLoss_G: 3.7375\tD(x): 0.9470\tD(G(z)): 0.1703 / 0.0295\n",
            "[116/250][0/29]\tLoss_D: 0.1776\tLoss_G: 3.3021\tD(x): 0.9265\tD(G(z)): 0.0928 / 0.0483\n",
            "[117/250][0/29]\tLoss_D: 0.4850\tLoss_G: 1.0192\tD(x): 0.6450\tD(G(z)): 0.0176 / 0.3996\n",
            "[118/250][0/29]\tLoss_D: 3.2883\tLoss_G: 2.4213\tD(x): 0.0665\tD(G(z)): 0.0015 / 0.1520\n",
            "[119/250][0/29]\tLoss_D: 0.2127\tLoss_G: 3.6741\tD(x): 0.8895\tD(G(z)): 0.0821 / 0.0381\n",
            "[120/250][0/29]\tLoss_D: 0.2564\tLoss_G: 3.4665\tD(x): 0.9192\tD(G(z)): 0.1479 / 0.0427\n",
            "[121/250][0/29]\tLoss_D: 0.2315\tLoss_G: 2.8263\tD(x): 0.8355\tD(G(z)): 0.0422 / 0.0785\n",
            "[122/250][0/29]\tLoss_D: 3.4214\tLoss_G: 0.1092\tD(x): 0.0684\tD(G(z)): 0.0151 / 0.9052\n",
            "[123/250][0/29]\tLoss_D: 0.3372\tLoss_G: 2.0060\tD(x): 0.7976\tD(G(z)): 0.0918 / 0.1590\n",
            "[124/250][0/29]\tLoss_D: 0.2485\tLoss_G: 2.7236\tD(x): 0.8256\tD(G(z)): 0.0472 / 0.0934\n",
            "[125/250][0/29]\tLoss_D: 0.2114\tLoss_G: 3.4756\tD(x): 0.9150\tD(G(z)): 0.1088 / 0.0426\n",
            "[126/250][0/29]\tLoss_D: 0.1868\tLoss_G: 2.7304\tD(x): 0.9052\tD(G(z)): 0.0779 / 0.0817\n",
            "[127/250][0/29]\tLoss_D: 1.0319\tLoss_G: 0.6761\tD(x): 0.4139\tD(G(z)): 0.0135 / 0.5616\n",
            "[128/250][0/29]\tLoss_D: 1.4212\tLoss_G: 1.4787\tD(x): 0.3076\tD(G(z)): 0.0076 / 0.3016\n",
            "[129/250][0/29]\tLoss_D: 0.2329\tLoss_G: 2.8210\tD(x): 0.8727\tD(G(z)): 0.0852 / 0.0805\n",
            "[130/250][0/29]\tLoss_D: 0.2325\tLoss_G: 3.9638\tD(x): 0.9301\tD(G(z)): 0.1398 / 0.0247\n",
            "[131/250][0/29]\tLoss_D: 0.1901\tLoss_G: 3.1373\tD(x): 0.8998\tD(G(z)): 0.0772 / 0.0551\n",
            "[132/250][0/29]\tLoss_D: 0.5324\tLoss_G: 2.6719\tD(x): 0.8413\tD(G(z)): 0.2654 / 0.0948\n",
            "[133/250][0/29]\tLoss_D: 0.2703\tLoss_G: 2.4789\tD(x): 0.8170\tD(G(z)): 0.0560 / 0.1101\n",
            "[134/250][0/29]\tLoss_D: 0.4211\tLoss_G: 5.5244\tD(x): 0.9602\tD(G(z)): 0.2924 / 0.0058\n",
            "[135/250][0/29]\tLoss_D: 0.2152\tLoss_G: 3.2848\tD(x): 0.9177\tD(G(z)): 0.1148 / 0.0485\n",
            "[136/250][0/29]\tLoss_D: 0.2268\tLoss_G: 3.7618\tD(x): 0.9469\tD(G(z)): 0.1510 / 0.0311\n",
            "[137/250][0/29]\tLoss_D: 0.1379\tLoss_G: 3.6332\tD(x): 0.9186\tD(G(z)): 0.0488 / 0.0360\n",
            "[138/250][0/29]\tLoss_D: 2.8361\tLoss_G: 0.3509\tD(x): 0.1057\tD(G(z)): 0.0426 / 0.7592\n",
            "[139/250][0/29]\tLoss_D: 0.9771\tLoss_G: 7.8285\tD(x): 0.9904\tD(G(z)): 0.5647 / 0.0008\n",
            "[140/250][0/29]\tLoss_D: 0.2113\tLoss_G: 3.4482\tD(x): 0.9225\tD(G(z)): 0.1152 / 0.0432\n",
            "[141/250][0/29]\tLoss_D: 0.1729\tLoss_G: 3.1891\tD(x): 0.9119\tD(G(z)): 0.0735 / 0.0560\n",
            "[142/250][0/29]\tLoss_D: 0.6069\tLoss_G: 1.3959\tD(x): 0.6185\tD(G(z)): 0.0395 / 0.3055\n",
            "[143/250][0/29]\tLoss_D: 0.3627\tLoss_G: 3.9940\tD(x): 0.8804\tD(G(z)): 0.1838 / 0.0303\n",
            "[144/250][0/29]\tLoss_D: 0.2101\tLoss_G: 3.8391\tD(x): 0.9362\tD(G(z)): 0.1287 / 0.0276\n",
            "[145/250][0/29]\tLoss_D: 0.1888\tLoss_G: 4.2752\tD(x): 0.9165\tD(G(z)): 0.0884 / 0.0211\n",
            "[146/250][0/29]\tLoss_D: 0.3442\tLoss_G: 6.0681\tD(x): 0.9855\tD(G(z)): 0.2618 / 0.0032\n",
            "[147/250][0/29]\tLoss_D: 1.4640\tLoss_G: 0.1929\tD(x): 0.3150\tD(G(z)): 0.0201 / 0.8380\n",
            "[148/250][0/29]\tLoss_D: 0.2157\tLoss_G: 4.4273\tD(x): 0.9464\tD(G(z)): 0.1398 / 0.0174\n",
            "[149/250][0/29]\tLoss_D: 0.1838\tLoss_G: 4.1142\tD(x): 0.9578\tD(G(z)): 0.1247 / 0.0229\n",
            "[150/250][0/29]\tLoss_D: 0.4464\tLoss_G: 5.9956\tD(x): 0.9894\tD(G(z)): 0.3288 / 0.0036\n",
            "[151/250][0/29]\tLoss_D: 0.1456\tLoss_G: 4.5206\tD(x): 0.9517\tD(G(z)): 0.0858 / 0.0156\n",
            "[152/250][0/29]\tLoss_D: 3.8225\tLoss_G: 0.3961\tD(x): 0.0438\tD(G(z)): 0.0012 / 0.7306\n",
            "[153/250][0/29]\tLoss_D: 1.3888\tLoss_G: 1.2364\tD(x): 0.3426\tD(G(z)): 0.0124 / 0.4052\n",
            "[154/250][0/29]\tLoss_D: 0.2975\tLoss_G: 3.8512\tD(x): 0.8710\tD(G(z)): 0.1273 / 0.0332\n",
            "[155/250][0/29]\tLoss_D: 0.3990\tLoss_G: 4.9194\tD(x): 0.9692\tD(G(z)): 0.2765 / 0.0102\n",
            "[156/250][0/29]\tLoss_D: 0.1898\tLoss_G: 3.2823\tD(x): 0.9074\tD(G(z)): 0.0824 / 0.0540\n",
            "[157/250][0/29]\tLoss_D: 0.1207\tLoss_G: 3.7695\tD(x): 0.9282\tD(G(z)): 0.0429 / 0.0358\n",
            "[158/250][0/29]\tLoss_D: 0.1101\tLoss_G: 3.6042\tD(x): 0.9490\tD(G(z)): 0.0541 / 0.0367\n",
            "[159/250][0/29]\tLoss_D: 0.1364\tLoss_G: 3.2470\tD(x): 0.9014\tD(G(z)): 0.0292 / 0.0574\n",
            "[160/250][0/29]\tLoss_D: 0.1402\tLoss_G: 4.5014\tD(x): 0.9618\tD(G(z)): 0.0915 / 0.0171\n",
            "[161/250][0/29]\tLoss_D: 1.1514\tLoss_G: 1.3930\tD(x): 0.4104\tD(G(z)): 0.0628 / 0.3387\n",
            "[162/250][0/29]\tLoss_D: 0.1915\tLoss_G: 2.9128\tD(x): 0.8706\tD(G(z)): 0.0446 / 0.0739\n",
            "[163/250][0/29]\tLoss_D: 0.1750\tLoss_G: 2.7025\tD(x): 0.8951\tD(G(z)): 0.0576 / 0.0881\n",
            "[164/250][0/29]\tLoss_D: 0.1683\tLoss_G: 3.0953\tD(x): 0.9424\tD(G(z)): 0.0987 / 0.0630\n",
            "[165/250][0/29]\tLoss_D: 0.1105\tLoss_G: 3.6738\tD(x): 0.9624\tD(G(z)): 0.0671 / 0.0321\n",
            "[166/250][0/29]\tLoss_D: 0.2086\tLoss_G: 5.4725\tD(x): 0.9785\tD(G(z)): 0.1613 / 0.0056\n",
            "[167/250][0/29]\tLoss_D: 0.1351\tLoss_G: 3.8235\tD(x): 0.9239\tD(G(z)): 0.0516 / 0.0323\n",
            "[168/250][0/29]\tLoss_D: 0.1007\tLoss_G: 3.9702\tD(x): 0.9466\tD(G(z)): 0.0433 / 0.0274\n",
            "[169/250][0/29]\tLoss_D: 0.6388\tLoss_G: 0.2923\tD(x): 0.5617\tD(G(z)): 0.0060 / 0.7799\n",
            "[170/250][0/29]\tLoss_D: 0.1599\tLoss_G: 3.7119\tD(x): 0.9365\tD(G(z)): 0.0859 / 0.0316\n",
            "[171/250][0/29]\tLoss_D: 0.1348\tLoss_G: 3.5567\tD(x): 0.9325\tD(G(z)): 0.0599 / 0.0391\n",
            "[172/250][0/29]\tLoss_D: 0.4617\tLoss_G: 8.3904\tD(x): 0.9923\tD(G(z)): 0.3408 / 0.0003\n",
            "[173/250][0/29]\tLoss_D: 0.1899\tLoss_G: 3.8174\tD(x): 0.9214\tD(G(z)): 0.0947 / 0.0305\n",
            "[174/250][0/29]\tLoss_D: 0.1466\tLoss_G: 3.9468\tD(x): 0.9586\tD(G(z)): 0.0957 / 0.0269\n",
            "[175/250][0/29]\tLoss_D: 0.1277\tLoss_G: 4.4526\tD(x): 0.9712\tD(G(z)): 0.0879 / 0.0157\n",
            "[176/250][0/29]\tLoss_D: 0.1043\tLoss_G: 3.7407\tD(x): 0.9631\tD(G(z)): 0.0619 / 0.0364\n",
            "[177/250][0/29]\tLoss_D: 0.1193\tLoss_G: 4.0583\tD(x): 0.9109\tD(G(z)): 0.0225 / 0.0263\n",
            "[178/250][0/29]\tLoss_D: 1.1493\tLoss_G: 5.4076\tD(x): 0.9757\tD(G(z)): 0.5895 / 0.0092\n",
            "[179/250][0/29]\tLoss_D: 0.3623\tLoss_G: 5.1274\tD(x): 0.9302\tD(G(z)): 0.2180 / 0.0136\n",
            "[180/250][0/29]\tLoss_D: 0.3079\tLoss_G: 2.7497\tD(x): 0.7603\tD(G(z)): 0.0139 / 0.1013\n",
            "[181/250][0/29]\tLoss_D: 0.1237\tLoss_G: 4.1152\tD(x): 0.9615\tD(G(z)): 0.0772 / 0.0238\n",
            "[182/250][0/29]\tLoss_D: 0.1036\tLoss_G: 4.0698\tD(x): 0.9590\tD(G(z)): 0.0571 / 0.0248\n",
            "[183/250][0/29]\tLoss_D: 0.1163\tLoss_G: 3.3061\tD(x): 0.9100\tD(G(z)): 0.0199 / 0.0514\n",
            "[184/250][0/29]\tLoss_D: 0.0902\tLoss_G: 3.7345\tD(x): 0.9583\tD(G(z)): 0.0450 / 0.0339\n",
            "[185/250][0/29]\tLoss_D: 3.5795\tLoss_G: 4.4944\tD(x): 0.9815\tD(G(z)): 0.9246 / 0.0241\n",
            "[186/250][0/29]\tLoss_D: 1.0204\tLoss_G: 7.3253\tD(x): 0.9920\tD(G(z)): 0.5407 / 0.0015\n",
            "[187/250][0/29]\tLoss_D: 0.1479\tLoss_G: 3.9296\tD(x): 0.9442\tD(G(z)): 0.0805 / 0.0292\n",
            "[188/250][0/29]\tLoss_D: 0.2090\tLoss_G: 4.9992\tD(x): 0.9821\tD(G(z)): 0.1622 / 0.0094\n",
            "[189/250][0/29]\tLoss_D: 0.1198\tLoss_G: 3.8333\tD(x): 0.9699\tD(G(z)): 0.0814 / 0.0292\n",
            "[190/250][0/29]\tLoss_D: 0.0955\tLoss_G: 4.0615\tD(x): 0.9451\tD(G(z)): 0.0369 / 0.0254\n",
            "[191/250][0/29]\tLoss_D: 0.1025\tLoss_G: 3.7588\tD(x): 0.9411\tD(G(z)): 0.0395 / 0.0337\n",
            "[192/250][0/29]\tLoss_D: 0.1061\tLoss_G: 4.7484\tD(x): 0.9712\tD(G(z)): 0.0715 / 0.0131\n",
            "[193/250][0/29]\tLoss_D: 3.5666\tLoss_G: 0.0464\tD(x): 0.0635\tD(G(z)): 0.0138 / 0.9560\n",
            "[194/250][0/29]\tLoss_D: 0.1372\tLoss_G: 3.8710\tD(x): 0.9406\tD(G(z)): 0.0690 / 0.0307\n",
            "[195/250][0/29]\tLoss_D: 0.0928\tLoss_G: 4.3540\tD(x): 0.9691\tD(G(z)): 0.0580 / 0.0186\n",
            "[196/250][0/29]\tLoss_D: 0.0971\tLoss_G: 3.3605\tD(x): 0.9391\tD(G(z)): 0.0323 / 0.0502\n",
            "[197/250][0/29]\tLoss_D: 0.0797\tLoss_G: 4.4245\tD(x): 0.9731\tD(G(z)): 0.0486 / 0.0171\n",
            "[198/250][0/29]\tLoss_D: 1.2351\tLoss_G: 0.3683\tD(x): 0.6144\tD(G(z)): 0.3391 / 0.7364\n",
            "[199/250][0/29]\tLoss_D: 0.3075\tLoss_G: 5.0971\tD(x): 0.9153\tD(G(z)): 0.1751 / 0.0106\n",
            "[200/250][0/29]\tLoss_D: 0.1019\tLoss_G: 3.7822\tD(x): 0.9546\tD(G(z)): 0.0520 / 0.0330\n",
            "[201/250][0/29]\tLoss_D: 0.1491\tLoss_G: 5.4119\tD(x): 0.9797\tD(G(z)): 0.1142 / 0.0060\n",
            "[202/250][0/29]\tLoss_D: 0.1038\tLoss_G: 4.2302\tD(x): 0.9883\tD(G(z)): 0.0849 / 0.0191\n",
            "[203/250][0/29]\tLoss_D: 0.1028\tLoss_G: 4.5116\tD(x): 0.9786\tD(G(z)): 0.0750 / 0.0157\n",
            "[204/250][0/29]\tLoss_D: 0.1197\tLoss_G: 2.7885\tD(x): 0.9042\tD(G(z)): 0.0168 / 0.0878\n",
            "[205/250][0/29]\tLoss_D: 0.0693\tLoss_G: 3.8246\tD(x): 0.9523\tD(G(z)): 0.0195 / 0.0319\n",
            "[206/250][0/29]\tLoss_D: 0.0631\tLoss_G: 4.0339\tD(x): 0.9682\tD(G(z)): 0.0292 / 0.0260\n",
            "[207/250][0/29]\tLoss_D: 0.0640\tLoss_G: 4.8494\tD(x): 0.9781\tD(G(z)): 0.0400 / 0.0123\n",
            "[208/250][0/29]\tLoss_D: 0.1044\tLoss_G: 5.3516\tD(x): 0.9885\tD(G(z)): 0.0858 / 0.0064\n",
            "[209/250][0/29]\tLoss_D: 0.0597\tLoss_G: 3.9396\tD(x): 0.9639\tD(G(z)): 0.0223 / 0.0269\n",
            "[210/250][0/29]\tLoss_D: 1.4404\tLoss_G: 2.3755\tD(x): 0.7594\tD(G(z)): 0.6201 / 0.1275\n",
            "[211/250][0/29]\tLoss_D: 1.1206\tLoss_G: 2.1517\tD(x): 0.4467\tD(G(z)): 0.0183 / 0.2183\n",
            "[212/250][0/29]\tLoss_D: 0.2729\tLoss_G: 5.9340\tD(x): 0.9532\tD(G(z)): 0.1769 / 0.0055\n",
            "[213/250][0/29]\tLoss_D: 0.1237\tLoss_G: 3.8021\tD(x): 0.9385\tD(G(z)): 0.0547 / 0.0335\n",
            "[214/250][0/29]\tLoss_D: 0.2184\tLoss_G: 3.2504\tD(x): 0.8237\tD(G(z)): 0.0117 / 0.0551\n",
            "[215/250][0/29]\tLoss_D: 0.0969\tLoss_G: 4.2693\tD(x): 0.9341\tD(G(z)): 0.0265 / 0.0217\n",
            "[216/250][0/29]\tLoss_D: 0.0998\tLoss_G: 4.1111\tD(x): 0.9771\tD(G(z)): 0.0709 / 0.0238\n",
            "[217/250][0/29]\tLoss_D: 0.1092\tLoss_G: 3.2239\tD(x): 0.9192\tD(G(z)): 0.0226 / 0.0580\n",
            "[218/250][0/29]\tLoss_D: 0.0678\tLoss_G: 4.0370\tD(x): 0.9629\tD(G(z)): 0.0288 / 0.0252\n",
            "[219/250][0/29]\tLoss_D: 0.5570\tLoss_G: 4.0338\tD(x): 0.8601\tD(G(z)): 0.2964 / 0.0267\n",
            "[220/250][0/29]\tLoss_D: 0.2209\tLoss_G: 5.8630\tD(x): 0.9875\tD(G(z)): 0.1725 / 0.0038\n",
            "[221/250][0/29]\tLoss_D: 0.0896\tLoss_G: 4.4373\tD(x): 0.9817\tD(G(z)): 0.0667 / 0.0163\n",
            "[222/250][0/29]\tLoss_D: 0.0732\tLoss_G: 3.8877\tD(x): 0.9724\tD(G(z)): 0.0428 / 0.0293\n",
            "[223/250][0/29]\tLoss_D: 0.0636\tLoss_G: 4.2510\tD(x): 0.9771\tD(G(z)): 0.0386 / 0.0212\n",
            "[224/250][0/29]\tLoss_D: 0.1081\tLoss_G: 2.4052\tD(x): 0.9153\tD(G(z)): 0.0181 / 0.1263\n",
            "[225/250][0/29]\tLoss_D: 0.1191\tLoss_G: 3.8648\tD(x): 0.9378\tD(G(z)): 0.0488 / 0.0291\n",
            "[226/250][0/29]\tLoss_D: 0.0856\tLoss_G: 4.1524\tD(x): 0.9558\tD(G(z)): 0.0379 / 0.0222\n",
            "[227/250][0/29]\tLoss_D: 0.0964\tLoss_G: 4.8578\tD(x): 0.9860\tD(G(z)): 0.0758 / 0.0109\n",
            "[228/250][0/29]\tLoss_D: 0.1565\tLoss_G: 6.6787\tD(x): 0.9931\tD(G(z)): 0.1288 / 0.0018\n",
            "[229/250][0/29]\tLoss_D: 0.0560\tLoss_G: 4.6195\tD(x): 0.9831\tD(G(z)): 0.0376 / 0.0144\n",
            "[230/250][0/29]\tLoss_D: 0.0543\tLoss_G: 4.2067\tD(x): 0.9734\tD(G(z)): 0.0264 / 0.0207\n",
            "[231/250][0/29]\tLoss_D: 0.0640\tLoss_G: 5.2059\tD(x): 0.9911\tD(G(z)): 0.0522 / 0.0082\n",
            "[232/250][0/29]\tLoss_D: 0.0567\tLoss_G: 4.2231\tD(x): 0.9607\tD(G(z)): 0.0161 / 0.0236\n",
            "[233/250][0/29]\tLoss_D: 0.0519\tLoss_G: 4.1413\tD(x): 0.9690\tD(G(z)): 0.0198 / 0.0235\n",
            "[234/250][0/29]\tLoss_D: 0.0465\tLoss_G: 5.0637\tD(x): 0.9865\tD(G(z)): 0.0317 / 0.0098\n",
            "[235/250][0/29]\tLoss_D: 0.0527\tLoss_G: 4.7388\tD(x): 0.9664\tD(G(z)): 0.0179 / 0.0136\n",
            "[236/250][0/29]\tLoss_D: 0.0417\tLoss_G: 4.5856\tD(x): 0.9784\tD(G(z)): 0.0194 / 0.0155\n",
            "[237/250][0/29]\tLoss_D: 2.4917\tLoss_G: 0.2798\tD(x): 0.1486\tD(G(z)): 0.0930 / 0.7845\n",
            "[238/250][0/29]\tLoss_D: 0.7203\tLoss_G: 8.2808\tD(x): 0.9562\tD(G(z)): 0.4209 / 0.0008\n",
            "[239/250][0/29]\tLoss_D: 0.7353\tLoss_G: 7.3741\tD(x): 0.9727\tD(G(z)): 0.4101 / 0.0014\n",
            "[240/250][0/29]\tLoss_D: 0.1737\tLoss_G: 5.4223\tD(x): 0.9804\tD(G(z)): 0.1305 / 0.0067\n",
            "[241/250][0/29]\tLoss_D: 0.0704\tLoss_G: 4.6691\tD(x): 0.9652\tD(G(z)): 0.0331 / 0.0146\n",
            "[242/250][0/29]\tLoss_D: 0.0832\tLoss_G: 3.9419\tD(x): 0.9409\tD(G(z)): 0.0207 / 0.0288\n",
            "[243/250][0/29]\tLoss_D: 0.0736\tLoss_G: 4.3714\tD(x): 0.9571\tD(G(z)): 0.0280 / 0.0202\n",
            "[244/250][0/29]\tLoss_D: 0.0664\tLoss_G: 4.0541\tD(x): 0.9634\tD(G(z)): 0.0279 / 0.0246\n",
            "[245/250][0/29]\tLoss_D: 0.0914\tLoss_G: 3.5921\tD(x): 0.9273\tD(G(z)): 0.0144 / 0.0412\n",
            "[246/250][0/29]\tLoss_D: 0.0650\tLoss_G: 4.0337\tD(x): 0.9541\tD(G(z)): 0.0172 / 0.0276\n",
            "[247/250][0/29]\tLoss_D: 0.1280\tLoss_G: 6.1770\tD(x): 0.9914\tD(G(z)): 0.1077 / 0.0031\n",
            "[248/250][0/29]\tLoss_D: 0.0726\tLoss_G: 3.4127\tD(x): 0.9535\tD(G(z)): 0.0238 / 0.0501\n",
            "[249/250][0/29]\tLoss_D: 0.0487\tLoss_G: 4.2891\tD(x): 0.9678\tD(G(z)): 0.0153 / 0.0198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzw4u67aoAvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOjLWsrdoHXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "\n",
        "HTML(ani.to_jshtml())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDiPk1ZwwSb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(netG.state_dict(), '/content/gdrive/My Drive/netG.pt')\n",
        "torch.save(netD.state_dict(), '/content/gdrive/My Drive/netD.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}